{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/eeg2text/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import datasets\n",
    "from datasets import load_dataset, Dataset\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn import metrics\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Flatten, SimpleRNN, Conv1D, TextVectorization\n",
    "from keras.utils import to_categorical\n",
    "from keras import regularizers, layers, Input, Model\n",
    "from tensorflow.keras.optimizers import AdamW, SGD\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import torch\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    }
   ],
   "source": [
    "# val_ds = load_dataset(\"groshanr/EEG2Text\", split=[f\"train[{k}%:{k+10}%]\" for k in range(0, 100, 10)])\n",
    "# train_ds = load_dataset(\"groshanr/EEG2Text\", split=[f\"train[:{k}%]+train[{k+10}%:]\" for k in range(0, 100, 10)])\n",
    "\n",
    "ds = load_dataset(\"groshanr/EEG2Text\", split = 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = mne.read_epochs(\"Murphy et al Dataset/session0_files0-151-epo/rsvp_session0_files0-11-epo.fif\")\n",
    "# eeg_data = epochs.get_data() # NumPy array of shape [n_trials, n_electrodes, n_timepoints] with n_electrodes = 64, n_timepoints = 276 and n_trials is variable by each file.\n",
    "# metadata = epochs.metadata   # Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['time', 'condition', 'Fp1', 'Fz', 'F3', 'F7', 'FT9', 'FC5', 'FC1', 'C3', 'T7', 'TP9', 'CP5', 'CP1', 'Pz', 'P3', 'P7', 'O1', 'Oz', 'O2', 'P4', 'P8', 'TP10', 'CP6', 'CP2', 'Cz', 'C4', 'T8', 'FT10', 'FC6', 'FC2', 'F4', 'F8', 'Fp2', 'AF7', 'AF3', 'AFz', 'F1', 'F5', 'FT7', 'FC3', 'C1', 'C5', 'TP7', 'CP3', 'P1', 'P5', 'PO7', 'PO3', 'POz', 'PO4', 'PO8', 'P6', 'P2', 'CPz', 'CP4', 'TP8', 'C6', 'C2', 'FC4', 'FT8', 'F6', 'AF8', 'AF4', 'F2', 'FCz', 'trigger', 'word', 'pos', 'sess', 'sent_num', 'filename', 'len', 'freq', 'sess_id', 'prev_pos', 'next_pos', 'prev_freq', 'next_freq', 'prev_len', 'next_len', 'sent_ident', '__index_level_0__'],\n",
      "    num_rows: 111560580\n",
      "})\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ds.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pos'] = df['pos'].astype('category')\n",
    "df['pos'] = df['pos'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=0.25) # Subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test split\n",
    "X = df[['Fp1', 'Fz', 'F3', 'F7', 'FT9', 'FC5', 'FC1', 'C3', 'T7', 'TP9', \n",
    "                'CP5', 'CP1', 'Pz', 'P3', 'P7','O1', 'Oz', 'O2', 'P4', 'P8', 'TP10', \n",
    "                'CP6', 'CP2', 'Cz', 'C4', 'T8', 'FT10', 'FC6', 'FC2', 'F4', 'F8', 'Fp2', \n",
    "                'AF7', 'AF3', 'AFz', 'F1', 'F5', 'FT7', 'FC3', 'C1', 'C5', 'TP7', 'CP3', \n",
    "                'P1', 'P5', 'PO7', 'PO3', 'POz', 'PO4', 'PO8', 'P6', 'P2', 'CPz', 'CP4', \n",
    "                'TP8', 'C6', 'C2', 'FC4', 'FT8', 'F6', 'AF8', 'AF4', 'F2', 'FCz']].values\n",
    "   \n",
    "\n",
    "y = df['pos'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn_filepath = 'best_rnn.keras'\n",
    "# rnn_checkpoint = ModelCheckpoint(filepath=rnn_filepath, \n",
    "#                              monitor='val_loss',\n",
    "#                              verbose=1, \n",
    "#                              save_best_only=True,\n",
    "#                              mode='min')\n",
    "# rnn_callbacks = [rnn_checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm_filepath = 'best_lstm.keras'\n",
    "# lstm_checkpoint = ModelCheckpoint(filepath=rnn_filepath,\n",
    "#                              monitor='val_loss',\n",
    "#                              verbose=1,\n",
    "#                              save_best_only=True,\n",
    "#                              mode='min')\n",
    "# lstm_callbacks = [lstm_checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple NN Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in kf.split(X, y):\n",
    "    x_train = X[train_index]\n",
    "    y_train = y[train_index]\n",
    "    x_test = X[test_index]\n",
    "    y_test = y[test_index]\n",
    "    y_train = to_categorical(y_train, num_classes=16)\n",
    "    y_test = to_categorical(y_test, num_classes=16)\n",
    "\n",
    "    model_rnn= Sequential()\n",
    "    model_rnn.add(Dense(256, input_dim = x_train.shape[1]))\n",
    "    model_rnn.add(Dense(256))\n",
    "    model_rnn.add(Dense(256))\n",
    "    model_rnn.add(Dense(16, activation='softmax'))\n",
    "    model_rnn.summary()\n",
    "\n",
    "# Train the model\n",
    "    opt = AdamW(learning_rate=0.0001)\n",
    "    model_rnn.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "    trained_model_base = model_rnn.fit(x_train, y_train, epochs=5, batch_size=64, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred = model_rnn.predict(x_test)\n",
    "y_pred_m = y_pred.reshape(y_pred.shape[0], y_pred.shape[2])\n",
    "y_test_m = y_test.reshape(y_test.shape[0], y_test.shape[2])\n",
    "y_pred_m = np.argmax(y_pred_m, axis=1)\n",
    "y_test_m = np.argmax(y_test_m, axis=1)\n",
    "print(classification_report(y_test_m, y_pred_m))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for train_index, test_index in kf.split(X, y):\n",
    "#     x_train = X[train_index]\n",
    "#     y_train = y[train_index]\n",
    "#     x_test = X[test_index]\n",
    "#     y_test = y[test_index]\n",
    "#     y_train = to_categorical(y_train)\n",
    "#     y_test = to_categorical(y_test)\n",
    "#     x_train = x_train.reshape(x_train.shape[0], -1, x_train.shape[1])\n",
    "#     x_test = x_test.reshape(x_test.shape[0], -1, x_test.shape[1])\n",
    "#     y_train = y_train.reshape(y_train.shape[0], -1, y_train.shape[1])\n",
    "#     y_test = y_test.reshape(y_test.shape[0], -1, y_test.shape[1])\n",
    "#     model_lstm = Sequential()\n",
    "#     model_lstm.add(layers.LSTM(64, return_sequences=True, input_shape=(x_train.shape[1],x_train.shape[2])))\n",
    "#     model_lstm.add(layers.LSTM(64, return_sequences=True))\n",
    "#     model_lstm.add(layers.LSTM(64, return_sequences=True))\n",
    "#     model_lstm.add(Dense(y_train.shape[2], activation='softmax'))\n",
    "#     model_lstm.summary()\n",
    "\n",
    "#     # Train the model\n",
    "#     opt = AdamW(learning_rate=0.001)\n",
    "#     model_lstm.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "#     trained_model_base = model_lstm.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "# y_pred = model_lstm.predict(x_test)\n",
    "# y_pred_m = y_pred.reshape(y_pred.shape[0], y_pred.shape[2])\n",
    "# y_test_m = y_test.reshape(y_test.shape[0], y_test.shape[2])\n",
    "# y_pred_m = np.argmax(y_pred_m, axis=1)\n",
    "# y_test_m = np.argmax(y_test_m, axis=1)\n",
    "# print(classification_report(y_test_m, y_pred_m))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg2text",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
